# D4.2 - Revised Intro + Literature Review
## Description
To write the section, avoid just summarizing each paper. Organize the papers, compare and 
contrast, identify gaps, and compare to your own work, stating the similarities and differences. 
You can break the section into subsections if you have different types of related work.
</br>
</br>Feedback from the previous deliverable should be incorporated at this new version. You should 
also add references to the introduction.

## 1. Revised Intro
The career ladder of a software developer consists of three levels: junior, middle, and senior. In order to determine salary level and responsibilites, the industry will refer to this terminology to understand and assign different degrees of qualification. Software developers are assigned to a degree of qualification based off their level of expertise in terms of: technical knowledge, day-to-day duties, independent work, and contributions to various software development projects. Being able to make this distinction between developers improves efficiency for interaction and interal communication. This means that companies search for developers with senior levels because it helps set more accurate expecations for a particular engineer. The easiest way to identify a senior level developer is by finding how many significant contributions they have made to a particular software project. However, newcomers in software development have difficulty contributing to projects due to their lack of experience.

Junior level developers gain knowledge being involved with projects, however they lack in making significant contributions. Previous work like the 'Theory of software developer expertise' has shown that concepts of "expert" and "expertise" within the field of software development and discovers additional findings on why senior-level developers may contribute more on GitHub compared to first-time developers. This is because more experience and knowledge for software developers are considered more in pull requests on GitHub. The tech industry is starting to have a shortage of software developers. This is because employers are faced by many challenges like software developers having a lack of experience, lack of technical skills, and lack of soft skills. Many software developers are still new to the tech industry and companies expect consistent high-quality history of software development skills. New software developers without the reputation and portfolio have to prove their place to get a job in this industry. Even if new software developers are inexperienced, it may be a good place where even for a small project on GitHub can serve them to be reliable. If we are able to solve this problem, new software developers will be able to get the experience they need, companies will no longer struggle with the massive shortage of programmers and software engineers, and there won't be a gap between first-time developers and senior-level developers on GitHub. From this study of the problem, first-time developers and the tech industry will benefit from it.

This paper seeks to provide an increased understanding of the average development path of junior level developers, by considering how the amount of time a developer has been contributing to open-source projects correlates to the rate at which their contributions are accepted. This addresses the problems by setting a baseline for the development of open-source contributors. This can highlight which developers need additional experience, encouraging them to seek out open-source projects to contribute to.


RQ 1: How many pull requests have been created on a particular Github project?
This will give us an idea of how many contributions are being made by various users on Github. From here, we will choose a few users at random to look further into their github history.
RQ 2: Refering to specific users, how many pull requests of theirs have been accepted?
This will give us data on how many pull requests a specific user has made on a project and how many of those have been accepted. This then tells us how many contributions were actually deemed significant to a project and we will compare the number of significant contributions between various users.

Our goal is to provide a better understanding of how the overall amount of time a developer has been contributing to open-source software relates to the number of contributions made by that developer, as well as how many of those contributions are considered to be “useful” enough to be accepted. This study will look at a number of pull requests made on open-source projects on GitHub. For each request, the experience of the user behind it (measured as the amount of time elapsed since the first GitHub contribution made by the user), the number of contributions made by that user, and whether the pull was merged will all be considered.

This research will give developers a frame of reference for how their own development compares to that of others in their field. This would be useful both to the developers themselves and to any professionals considering hiring them, as it would allow them to compare their own experience to the experience of the average developer. This would show which candidates have a history of high or low performance in open-source contributions.## 2. Related Works
## 2. Related Works
This section presents the existing research in open source software communities. There are different approaches by researchers and organizations to understand the factors affecting pull requests and code quality.

### 2.1 Background 
Previous papers have looked into the relationships between developer experience, code acceptance, and code quality. In particular, these papers have found the factors that impact the likelihood of pull request acceptance [1][3][4][5]. 
They also considered how pull request acceptance can itself impact future behavior [2], and how certain factors can also impact the amount of time it takes for a pull request to be accepted or rejected [6]. 
These begin to show the ways in which the factors surrounding a pull request and the user making the request interact with one another.
### 2.2 Related Work
  Tresa Rose [1] were one of the researchers that studied open source software (OSS) communities. They performed two types of studies, qualitative and quantitative, which investigated pull request merges of Shopify projects available in its public repository, Active Merchant. They performed a quantitative study by data mining on the project's GitHub repository to see the types of merges followed by Shopify developers. Their qualitative study was performing a survey on the Shopify developers who contributed to Active Merchant. They found that "pull request size, number of people involved in discussion, commits count, and organization of the contributor" are all factors affecting the decision to merge pull requests. 
  
  Legay, Decan, and Mens [2] studied the impact of pull request decisions on future contributions in GitHub. They had to consider the potential effects of rejections or ignored pull requests on further contributions. They did this by studying three large projects on GitHub, obtaining data through GitHub API using pull request data, and performing analyses to investigate pull requests decisions. They found that continued contribution to a project correlates with a higher pull request acceptance rate and pull requests rejections lead to fewer future contributions. 
  
  Soares, Lima, Murta, and Plastino [3] studied rejection factors of pull requests filed by core team developers in software projects with high acceptance rates. They extracted association rules from pull request data stored in software repositories in order to find factors that may have influenced these decisions. A qualitative analyses was performed to help them understand the patterns from the association rules. "Inexperience with pull requests, complexity of contributions, as well as the locality of the artifacts that have been modified, and the contribution policy of the projects" were the key factors found that increased the changes of having internal contributions rejected. 
  
  Lenarduzzi, Nikkola, Saarimäki, and Taibi [4] conducted a case study among 28 Java open-source projects to find out if code quality affect pull requests. They analyzed the correlation of 4.7 million code quality flaws in 36,000 pull requests by applying logistic regression and six machine learning techniques. They found that these code quality flaws did not affect the acceptance of a pull request at all. However, the reputation of the maintainer and the importance of delivered feature were the factors of pull request acceptance. 
  
  Dey and Mockus [5] did a study on which pull requests get accepted and why. In order to answer this, they modeled the probability that a pull request will be accepted within a month of being created using a Random Forest model using 483,988 pull rquests from 4,218 popular NPM packages. As a result, an AUC-ROC value of 0.95 was achieved to predict pull request acceptance. They tested the utility of the Random Forest model in practical scenarios. They had to train it with historical data from the NPM package bootstrap and predict if in the future, any pull request that is submitted will be accepted.
  
  Yu, Wang, Filkov, Devanbu, and Vasilescu [6] studied the determinants of pull request evaluation latency on GitHub. They did a quantitative study that tries to resolve which factors affected pull request evaluation latency in GitHub. To extract data from a sample of GitHub projects, they used a regression model and the Travis-CI continuous integration service. They found that pull requests with "more discussion, consisting of more commits, and adding more lines of code" are factors associated with longer evaluation latencies.

### 2.3 Comparisons to our study

## References 
[1] Rose, T. (2017). Towards understanding what factors a ECT by Tresa rose a ... Retrieved October 14, 2021, from https://curve.carleton.ca/system/files/etd/4d6605dd-eed2-4b0f-b1e1-1b92f6dea244/etd_pdf/d102ad239b0371a72a1c5c43978d82bd/rose-towardsunderstandingwhatfactorsaffectpull.pdf. 

[2] Legay, D., Decan, A., & Mens, T. (2018, December 15). On the impact of pull request decisions on future contributions. Retrieved October 14, 2021, from https://arxiv.org/abs/1812.06269.

[3] Soares, D. M., De Lima, M. L., Murta, L., & Plastino, A. (2015, December 9). Rejection factors of pull requests filed by CORE team developers in software projects with high acceptance rates. Retrieved October 14, 2021, from https://ieeexplore.ieee.org/abstract/document/7424445. 

[4] Lenarduzzi, V., Nikkola, V., Saarimäki, N., & Taibi, D. (2020, August 28). Does code quality affect pull request acceptance? an empirical study. Retrieved October 14, 2021, from https://www.sciencedirect.com/science/article/pii/S0164121220302090. 

[5] Dey, T., & Mockus, A. (2020, March 2). Which pull requests get accepted and why? A study of popular NPM Packages. Retrieved October 14, 2021, from https://arxiv.org/abs/2003.01153. 

[6] Yu, Y., Wang, H., Filkov, V., Devanbu, P., & Vasilescu, B. (2015). Wait for it: Determinants of pull request evaluation latency on github. 2015 IEEE/ACM 12th Working Conference on Mining Software Repositories. https://doi.org/10.1109/msr.2015.42 

## Format
LaTex document -> submitted as a pdf.
## Grading Criteria
1. How well did you cover the literature (3 pts): Did you find the most significant related papers? 
Are there enough papers? 
2. How well you organized the related work (3 pts): Do you group the papers into meaningful 
sections/paragraphs? Do you compare and contrast them?
3. How well do you compare the related work to your own work? (3 pts): Do you 
identify the gaps? Do you make clear the similarities and the similarities to your own proposal?
4. How well did you write the section (3 pts): Do you follow the ACM template? Is the text 
fluid and do the ideas follow a logical order? Is the text grammatically correct? Is the language appropriate for 
academic writing?
5. Did you changed the text based on the feedback received in the last 
deliverable? (3 pts)
